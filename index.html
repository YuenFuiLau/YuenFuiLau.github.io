<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <!--a href="https://pages.github.com/">Tianjia Zhang</a>,-->
              <p>Tianjia Zhang,</p>
            </span>
            <span class="author-block">
              <!--a href="https://www.linkedin.com/in/lau-yuen-fui-amir-a92a421a4/">Yuen Fui Lau</a>,-->
              <p>Yuen-Fui Lau,</p>
            </span>
            <span class="author-block">
              <a href="https://cqf.io/">Qifeng Chen</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">The Hong Kong University of Science and Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="pending for paper link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/embed/IUmy1LBCVhc"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/YuenFuiLau/A-Portable-Multiscopic-Camera-for-Novel-View-and-Time-Synthesis-in-Dynamic-Scenes"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> 
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1dHoym_SdY2FkzZ6fIPl0Xp76_Lg0wxIQ?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-room7_img">
          <img src="./static/video/room7_img.gif">
        </div>
        <div class="item item-room2_img">
          <img src="./static/video/room2_img.gif">
        </div>
        <div class="item item-room8_img">
          <img src="./static/video/room8_img.gif">
        </div>
        <div class="item item-room4_img">
          <img src="./static/video/room4_img.gif">
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present a portable multiscopic camera system
            with a dedicated model for novel view and time synthesis in
            dynamic scenes. Our goal is to render high-quality images
            for a dynamic scene from any viewpoint at any time using
            our portable multiscopic camera. To achieve such novel view
            and time synthesis, we develop a physical multiscopic camera
            equipped with five cameras to train a neural radiance field
            (NeRF) in both time and spatial domains for dynamic scenes.
            Our model maps a 6D coordinate (3D spatial position, 1D temporal coordinate, and 2D viewing direction) to view-dependent
            and time-varying emitted radiance and volume density. Volume
            rendering is applied to render a photo-realistic image at a specified camera pose and time. To improve the robustness of our
            physical camera, we propose a camera parameter optimization
            module and a temporal frame interpolation module to promote
            information propagation across time. We conduct experiments
            on both real-world and synthetic datasets to evaluate our
            system, and the results show that our approach outperforms
            alternative solutions qualitatively and quantitatively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!--/ Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            From several multiscopic input videos or images, we learn a time-varying scene
            representation to model the geometry and appearance of the scene. From
            such representation, we can generate novel images (red line) at any pose
            (a) and time (b).
          </p>
        </div>
        <div>
          <img src="./static/images/method.png" alt="method" class="center">
        </div>
      </div>
    </div>

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/IUmy1LBCVhc?rel=0&showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>

  <br>
  <br>

  <!--/ pipline. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Pipline</h2>
      <div class="content has-text-justified">
        <p>
          Our objective is to render a target image I<sub>t</sub> with the specified
          target pose P at time t. To address the problem, we formulate
          the neural radiance field as a function of a 4D space-time
          coordinate (x, y, z, t) and a 2D viewing direction d. The
          output consists of time-dependent radiance c<sub>t</sub> and volume
          density &sigma;<sub>t</sub>. To exploit and integrate the visual consistency
          information across time, we apply the frame interpolation
          method to generate intermediate frames, which serve
          as extra ground-truth to supervise the training process. If the
          camera parameters are unknown, we simultaneously optimize
          the intrinsic parameter in normal space and the extrinsic
          parameters in SE(3) space.
        </p>
      </div>
      <div>
        <img src="./static/images/pipline.png" alt="method" class="center">
      </div>
    </div>
  </div>

</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Render Depth</h2>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-room7_depth">
          <img src="./static/video/room7_depth.gif">
        </div>
        <div class="item item-room2_depth">
          <img src="./static/video/room2_depth.gif">
        </div>
        <div class="item item-room8_depth">
          <img src="./static/video/room8_depth.gif">
        </div>
        <div class="item item-room4_depth">
          <img src="./static/video/room4_depth.gif">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Visual Effects. -->
    <div class="column">
      <div class="content">
        <h2 class="title is-2">Novel view and time synthesis for image in the wild</h2>
      </div>
    </div>

    <div class="columns is-centered">

      <!-- Interior -->
      <div class="column">
        <div class="content">
          <h3 class="title is-3">Indoor Environment</h3>
          <p>
            You can render novel view across time in indoor area
          </p>
          <br>
          <img src="./static/video/room1_img.gif" style="width:80%">
          <br>
          <br>
          <img src="./static/video/room1_depth.gif" style="width:80%">
          <br>
        </div>
      </div>
      <!--/ Interior -->

      <!-- Exterior. -->
      <div class="column">
        <h3 class="title is-3">Outdoor Environment</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              You can render novel view across time in outdoor area
            </p>
            <br>
            <img src="./static/video/room6_img.gif" style="width:80%">
            <br>
            <br>
            <img src="./static/video/room6_depth.gif" style="width:80%">
            <br>
          </div>
        </div>
      </div>
    </div>
    <!--/ Exterior. -->

    <!-- Concurrent Work. -->
    <!--<div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>-->
    <!--/ Concurrent Work. -->

  </div>
</section>



<!--<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>-->


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The <a href="https://github.com/nerfies/nerfies.github.io">source code</a> for the website was taken from Nerfies. We appreciate the authors sharing the templates with us.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
